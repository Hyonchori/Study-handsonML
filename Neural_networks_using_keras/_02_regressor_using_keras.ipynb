{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "special-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "continuous-sellers",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "x_train_full, x_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target)\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train_full, y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_val = scaler.transform(x_val)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "protected-struggle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11610, 8), (3870, 8), (5160, 8))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_val.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "finnish-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=x_train.shape[1: ]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "important-horror",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 749us/step - loss: 1.3986 - val_loss: 0.4900\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 470us/step - loss: 0.5341 - val_loss: 0.4362\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 463us/step - loss: 0.5262 - val_loss: 0.4168\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 535us/step - loss: 0.4806 - val_loss: 0.4129\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 473us/step - loss: 0.4372 - val_loss: 0.3893\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 463us/step - loss: 0.4202 - val_loss: 0.3884\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 464us/step - loss: 0.4353 - val_loss: 0.3747\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 522us/step - loss: 0.4136 - val_loss: 0.3790\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 470us/step - loss: 0.4167 - val_loss: 0.3635\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 497us/step - loss: 0.4184 - val_loss: 0.3627\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 470us/step - loss: 0.4068 - val_loss: 0.3755\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 525us/step - loss: 0.3974 - val_loss: 0.3642\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 497us/step - loss: 0.3808 - val_loss: 0.7906\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 497us/step - loss: 0.5017 - val_loss: 0.3717\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 498us/step - loss: 0.4106 - val_loss: 0.3565\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 507us/step - loss: 0.3803 - val_loss: 0.3523\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 482us/step - loss: 0.4031 - val_loss: 0.3810\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 496us/step - loss: 0.3849 - val_loss: 0.3601\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 504us/step - loss: 0.4241 - val_loss: 0.5218\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 485us/step - loss: 0.4120 - val_loss: 0.3575\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train, epochs=20, \n",
    "                validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "biological-character",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 311us/step - loss: 0.4736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47358909249305725"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test = model.evaluate(x_test, y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "atlantic-section",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.81721294],\n",
       "        [2.283176  ],\n",
       "        [2.177102  ]], dtype=float32),\n",
       " array([0.723, 4.1  , 2.441]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new = x_test[: 3]\n",
    "y_pred = model.predict(x_new)\n",
    "y_pred, y_test[: 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-track",
   "metadata": {},
   "source": [
    "시퀀셜 API를 사용해 회귀용 MLP를 구축, 학습, 평가, 예측하는 방법은 이전에 분류에서 했던 것과 매우 비슷함.  \n",
    "다른 점은 출력층이 활성화 함수가 없는 하나의 뉴런(하나의 값을 예측하는 경우)이라는 것과 손실 함수로 평균 제곱 오차를 이용한다는 점임.  \n",
    "이 데이터셋은 잡음이 많기 때문에 과대적합을 막는 용도로 뉴런 수가 적은 은닉층 하나만 사용했다고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-dutch",
   "metadata": {},
   "source": [
    "---\n",
    "## 함수형 API를 사용해 복잡한 모델 만들기\n",
    "순차적이지 않은 신경말을 구현하기 위해 함수형 API 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "honey-samuel",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=x_train.shape[1: ])\n",
    "h1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "h2 = keras.layers.Dense(30, activation=\"relu\")(h1)\n",
    "concat = keras.layers.Concatenate()([input_, h2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "\n",
    "model1 = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-executive",
   "metadata": {},
   "source": [
    "함수형 API를 이용해 **와이드 & 딥 신경망** 을 구현한 모습  \n",
    ">해당 모델은 입력값의 일부 또는 전체가 출력층에 바로 연결되는 특징을 갖고 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "infrared-swimming",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_b = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "h1 = keras.layers.Dense(30, activation=\"relu\")(input_b)\n",
    "h2 = keras.layers.Dense(30, activation=\"relu\")(h1)\n",
    "concat = keras.layers.Concatenate()([input_a, h2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "\n",
    "model2 = keras.Model(inputs=[input_a, input_b], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-citizen",
   "metadata": {},
   "source": [
    "입력의 일부는 깊은 경로(일반적인 피드포워드 경로)로 가고 일부는 짧은 경로(출력층과 바로 이어진)로 가게 설정하기 위해선  \n",
    "위와 같이 멀티 입력을 설정하면 됨.  \n",
    "이렇게 모델이 복잡해지면 중요한 층에는 이름을 붙이는 것이 좋음.  \n",
    "그리고 입력이 나눠지면 fit메서드를 호출할 때도 입력마다 하나씩 행렬의 튜플을 전달해야 함 : **(x_train_a, x_train_b)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sunset-roman",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 785us/step - loss: 3.6700 - val_loss: 0.7849\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 547us/step - loss: 0.7737 - val_loss: 0.6756\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 539us/step - loss: 0.6667 - val_loss: 0.6095\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 544us/step - loss: 0.6613 - val_loss: 0.5762\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 542us/step - loss: 0.6236 - val_loss: 0.5505\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 561us/step - loss: 0.5881 - val_loss: 0.5379\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 536us/step - loss: 0.5648 - val_loss: 0.5128\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 538us/step - loss: 0.5504 - val_loss: 0.5063\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 529us/step - loss: 0.5419 - val_loss: 0.4878\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 539us/step - loss: 0.5245 - val_loss: 0.4783\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 518us/step - loss: 0.5108 - val_loss: 0.4699\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 518us/step - loss: 0.5092 - val_loss: 0.4647\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 520us/step - loss: 0.4909 - val_loss: 0.4534\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 517us/step - loss: 0.4700 - val_loss: 0.4514\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 519us/step - loss: 0.5084 - val_loss: 0.4447\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 519us/step - loss: 0.4694 - val_loss: 0.4386\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 541us/step - loss: 0.4716 - val_loss: 0.4371\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 528us/step - loss: 0.4765 - val_loss: 0.4287\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 531us/step - loss: 0.4608 - val_loss: 0.4261\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 527us/step - loss: 0.4589 - val_loss: 0.4233\n"
     ]
    }
   ],
   "source": [
    "model1.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=0.001))\n",
    "hist = model1.fit(x_train, y_train, epochs=20,\n",
    "                 validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "authorized-sheep",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 758us/step - loss: 3.2910 - val_loss: 1.0994\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 536us/step - loss: 0.9669 - val_loss: 0.7665\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 534us/step - loss: 0.7571 - val_loss: 0.6602\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 538us/step - loss: 0.7040 - val_loss: 0.5995\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 549us/step - loss: 0.6230 - val_loss: 0.5628\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 553us/step - loss: 0.5909 - val_loss: 0.5356\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 577us/step - loss: 0.5702 - val_loss: 0.5142\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 589us/step - loss: 0.5426 - val_loss: 0.4975\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 594us/step - loss: 0.5420 - val_loss: 0.4848\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 583us/step - loss: 0.4945 - val_loss: 0.4730\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 554us/step - loss: 0.5349 - val_loss: 0.4638\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 554us/step - loss: 0.4887 - val_loss: 0.4582\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 559us/step - loss: 0.4844 - val_loss: 0.4540\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 600us/step - loss: 0.4892 - val_loss: 0.4439\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 568us/step - loss: 0.4749 - val_loss: 0.4394\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 566us/step - loss: 0.4912 - val_loss: 0.4338\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 564us/step - loss: 0.4600 - val_loss: 0.4339\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 583us/step - loss: 0.4584 - val_loss: 0.4275\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 611us/step - loss: 0.4633 - val_loss: 0.4229\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 562us/step - loss: 0.4537 - val_loss: 0.4213\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=0.001))\n",
    "\n",
    "x_train_a, x_train_b = x_train[:, :5], x_train[:, 2:]\n",
    "x_val_a, x_val_b = x_val[:, :5], x_val[:, 2:]\n",
    "x_test_a, x_test_b = x_test[:, :5], x_test[:, 2:]\n",
    "\n",
    "hist = model2.fit((x_train_a, x_train_b), y_train, epochs=20,\n",
    "                 validation_data=((x_val_a, x_val_b), y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-reference",
   "metadata": {},
   "source": [
    "여러개의 출력이 필요한 경우도 많음.  \n",
    "- 그림에 있는 주요 물체를 분류하고 위치를 알아야 할 때 회귀 작업(물체 중심의 좌표, 너비, 높이)과 분류 작업을 함께 할 때.  \n",
    "- 동일한 데이터에서 독립적인 여러 작업을 수행할 때. 작업마다 다른 신경망을 각각 학습하는 것이 보통 더 나은 결과를 내지만 신경망이 여러 작업에 걸쳐 유용한 특성을 학습하기 때문에 다중 작업 분류가 가능(예를 들어 한 출력은 사람의 얼굴 표정 분류, 다른 출력은 안경을 썼는지 분류를 할 수 있음)  \n",
    "- 규제 기법으로 사용하는 경우. 예를 들어 신경망 안에 보조 출력을 추가하여 하위 네트워크가 나머지 네트워크에 의존하지 않고 그 자체로 유용한지 학습하는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "thorough-chapel",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_b = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "h1 = keras.layers.Dense(30, activation=\"relu\")(input_b)\n",
    "h2 = keras.layers.Dense(30, activation=\"relu\")(h1)\n",
    "concat = keras.layers.Concatenate()([input_a, h2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(h2)\n",
    "\n",
    "model3 = keras.Model(inputs=[input_a, input_b], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "built-bookmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-saskatchewan",
   "metadata": {},
   "source": [
    "각 출력은 자신만의 손실함수가 필요함. 따라서 모델을 컴파일할 때 손실의 리스트를 전달해야 함.(하나의 손실만 전달하면 케라스는 모든 출력의 손실함수가 동일하다고 가정함)  \n",
    "기본적으로 케라스는 나열된 손실을 모두 더하여 최종 손실을 구해 학습에 사용함. \n",
    ">보조 출력보다 주 출력에 관심이 더 많다면 주 출력에 더 많은 가중치를 두면 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "regional-sunday",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 693us/step - loss: 0.3731 - main_output_loss: 0.3622 - aux_output_loss: 0.4710 - val_loss: 0.3387 - val_main_output_loss: 0.3269 - val_aux_output_loss: 0.4452\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 605us/step - loss: 0.3705 - main_output_loss: 0.3597 - aux_output_loss: 0.4676 - val_loss: 0.3282 - val_main_output_loss: 0.3171 - val_aux_output_loss: 0.4272\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 625us/step - loss: 0.3694 - main_output_loss: 0.3591 - aux_output_loss: 0.4621 - val_loss: 0.3286 - val_main_output_loss: 0.3179 - val_aux_output_loss: 0.4245\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 632us/step - loss: 0.3671 - main_output_loss: 0.3571 - aux_output_loss: 0.4569 - val_loss: 0.3243 - val_main_output_loss: 0.3136 - val_aux_output_loss: 0.4203\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 622us/step - loss: 0.3650 - main_output_loss: 0.3550 - aux_output_loss: 0.4550 - val_loss: 0.3242 - val_main_output_loss: 0.3135 - val_aux_output_loss: 0.4209\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 611us/step - loss: 0.3649 - main_output_loss: 0.3552 - aux_output_loss: 0.4528 - val_loss: 0.3245 - val_main_output_loss: 0.3142 - val_aux_output_loss: 0.4174\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 613us/step - loss: 0.3635 - main_output_loss: 0.3537 - aux_output_loss: 0.4510 - val_loss: 0.3222 - val_main_output_loss: 0.3119 - val_aux_output_loss: 0.4146\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 612us/step - loss: 0.3636 - main_output_loss: 0.3543 - aux_output_loss: 0.4477 - val_loss: 0.3274 - val_main_output_loss: 0.3174 - val_aux_output_loss: 0.4175\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 629us/step - loss: 0.3588 - main_output_loss: 0.3489 - aux_output_loss: 0.4471 - val_loss: 0.3187 - val_main_output_loss: 0.3085 - val_aux_output_loss: 0.4098\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 622us/step - loss: 0.3578 - main_output_loss: 0.3483 - aux_output_loss: 0.4435 - val_loss: 0.3326 - val_main_output_loss: 0.3228 - val_aux_output_loss: 0.4206\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 644us/step - loss: 0.3596 - main_output_loss: 0.3504 - aux_output_loss: 0.4427 - val_loss: 0.3184 - val_main_output_loss: 0.3086 - val_aux_output_loss: 0.4060\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 649us/step - loss: 0.3547 - main_output_loss: 0.3456 - aux_output_loss: 0.4367 - val_loss: 0.3252 - val_main_output_loss: 0.3158 - val_aux_output_loss: 0.4093\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 644us/step - loss: 0.3585 - main_output_loss: 0.3496 - aux_output_loss: 0.4384 - val_loss: 0.3247 - val_main_output_loss: 0.3146 - val_aux_output_loss: 0.4160\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 649us/step - loss: 0.3545 - main_output_loss: 0.3454 - aux_output_loss: 0.4362 - val_loss: 0.3266 - val_main_output_loss: 0.3181 - val_aux_output_loss: 0.4030\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 631us/step - loss: 0.3535 - main_output_loss: 0.3447 - aux_output_loss: 0.4328 - val_loss: 0.3145 - val_main_output_loss: 0.3048 - val_aux_output_loss: 0.4019\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 630us/step - loss: 0.3704 - main_output_loss: 0.3627 - aux_output_loss: 0.4400 - val_loss: 0.3203 - val_main_output_loss: 0.3111 - val_aux_output_loss: 0.4033\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 636us/step - loss: 0.3544 - main_output_loss: 0.3459 - aux_output_loss: 0.4311 - val_loss: 0.3161 - val_main_output_loss: 0.3071 - val_aux_output_loss: 0.3971\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 641us/step - loss: 0.3856 - main_output_loss: 0.3806 - aux_output_loss: 0.4306 - val_loss: 0.3216 - val_main_output_loss: 0.3112 - val_aux_output_loss: 0.4156\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 673us/step - loss: 0.3534 - main_output_loss: 0.3445 - aux_output_loss: 0.4333 - val_loss: 0.3379 - val_main_output_loss: 0.3288 - val_aux_output_loss: 0.4204\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 671us/step - loss: 0.3535 - main_output_loss: 0.3453 - aux_output_loss: 0.4273 - val_loss: 0.3164 - val_main_output_loss: 0.3072 - val_aux_output_loss: 0.3989\n"
     ]
    }
   ],
   "source": [
    "hist = model3.fit((x_train_a, x_train_b), y_train, epochs=20,\n",
    "          validation_data=((x_val_a, x_val_b), y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "quarterly-throw",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 702us/step - loss: 0.3209 - main_output_loss: 0.3112 - aux_output_loss: 0.4081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3208684027194977, 0.3111749291419983, 0.40811002254486084)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model3.evaluate([x_test_a, x_test_b], [y_test, y_test])\n",
    "total_loss, main_loss, aux_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "conscious-sound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.9050157],\n",
       "        [2.3326054],\n",
       "        [2.6610227]], dtype=float32),\n",
       " array([[0.8577765],\n",
       "        [2.2640398],\n",
       "        [2.8308058]], dtype=float32))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new_a = x_test_a[: 3]\n",
    "x_new_b = x_test_b[: 3]\n",
    "y_pred_main, y_pred_aux = model3.predict([x_new_a, x_new_b])\n",
    "y_pred_main, y_pred_aux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-baseball",
   "metadata": {},
   "source": [
    "---\n",
    "## 서브클래싱 API로 동적 모델 만들기\n",
    "시퀀셜 API와 함수형 API 모두 선언적임. 사용할 층과 연결 방식을 먼저 정의해야 하고 그 다음 모델에 데이터를 주입하여 학습이나 예측을 시작할 수 있음. 이 방식에는 장점이 많음.  \n",
    "- 모델을 저장하거나 복사, 공유가 쉬움.  \n",
    "- 모델의 구조를 출력하거나 분석하기 좋음.  \n",
    "- 프레임워크가 크기를 짐작하고 타입을 확인하여 에러를 일찍 발견할 수 있음.(모델에 데이터가 주입되기 전에)  \n",
    "- 전체 모델이 층으로 구성된 정적 그래프이므로 디버깅하기 쉬움.  \n",
    "  \n",
    "하지만 어떤 모델은 반복문을 포함하고 다양한 크기를 다루어야 하며 조건문을 가지는 등 여러가지 동적인 구조를 필요로 함.  \n",
    "이런 경우 **서브클래싱 API** 가 정담임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "younger-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.h1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.h2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        input_a, input_b = inputs\n",
    "        h1 = self.h1(input_b)\n",
    "        h2 = self.h2(h1)\n",
    "        concat = keras.layers.concatenate([input_a, h2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(h2)\n",
    "        return main_outpur, aux_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-evanescence",
   "metadata": {},
   "source": [
    "간단히 Model클래스를 상속한 다음 생성자 안에서 필요한 층을 만듦.  \n",
    "그 다음 **call()** 메서드 안에서 수행하려는 연산을 기술함.  \n",
    "이 예제는 함수형 API와 비슷하지만 Input클래스의 객체를 만들 필요가 없음. 대신 call()메서드의 input 매개변수를 사용함.  \n",
    ">주된 차이점은 call()메서드 안에서 원하는 어떤 계산도 사용할 수 있음.  \n",
    "for문, if문, 텐서플로의 저수준 연산도 사용할 수 있음.  \n",
    "  \n",
    "하지만 모델 구조가 call()메서드 안에 숨겨져 있기 때문에 케라스가 쉽게 이를 분석할 수 없다고 함.  \n",
    "**즉 모델을 저장하거나 복사할 수 없음** (????? 그럼 왜씀??)  \n",
    "summary()메서드를 호출해도 층의 목록만 나열되고 층 간의 연결 정보를 얻을 수 없음.  \n",
    "> 그래서 높은 유연성이 필요하지 않다면 그냥 시퀀셜이나 함수형 API 사용하는 것이 좋다고 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "coordinated-russell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "deep_input (InputLayer)         [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 30)           210         deep_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "wide_input (InputLayer)         [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 30)           930         dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 35)           0           wide_input[0][0]                 \n",
      "                                                                 dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 1)            36          concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "aux_output (Dense)              (None, 1)            31          dense_17[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,207\n",
      "Trainable params: 1,207\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-survival",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
