{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "demonstrated-header",
   "metadata": {},
   "source": [
    "# 입력 특성 전처리하기\n",
    "신경망을 위해 데이터를 준비하려면 일반적으로 모든 특성은 **수치 특성으로 변환하고 정규화해야 함**  \n",
    ">특히 범주형 특성이나 텍스트 특성이 있다면 숫자로 바꿔야 함.\n",
    "\n",
    "어떤 도구라도 이용해서(넘파이, 판다스, 사이킷런) 데이터 파일을 준비하기 전에 처리해야 함. 아니면 **데이터 API** 로 적재할 때 동적으로 전처리할 수도 있음.  \n",
    "> 또는 **전처리 층** 을 따로 만들어서 모델에 직접 포함시킬 수도 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "black-stability",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    os.makedirs(housing_path, exist_ok=True)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pediatric-palace",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "generous-webster",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "expired-martial",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = load_housing_data()\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "communist-democrat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-intro",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. 정규화\n",
    "### 1.1 전역변수 사용\n",
    ">각 특성의 평균, 표준편차를 미리 계산하여 전처리하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "postal-chicken",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16512, 9), (16512, 1))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n",
    "train_num_set = train_set.drop(\"ocean_proximity\", axis=1)\n",
    "train_cat_set = train_set[[\"ocean_proximity\"]]\n",
    "train_num_set.shape, train_cat_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "jewish-painting",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9,)\n",
      "\n",
      "(9,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "means = np.mean(train_num_set, axis=0)\n",
    "stds = np.std(train_num_set, axis=0)\n",
    "print(means.shape)\n",
    "print(\"\")\n",
    "print(stds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "honey-viewer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14196</th>\n",
       "      <td>1.272587</td>\n",
       "      <td>-1.372811</td>\n",
       "      <td>0.348490</td>\n",
       "      <td>0.222569</td>\n",
       "      <td>0.211228</td>\n",
       "      <td>0.768276</td>\n",
       "      <td>0.322906</td>\n",
       "      <td>-0.326196</td>\n",
       "      <td>-0.901189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8267</th>\n",
       "      <td>0.709162</td>\n",
       "      <td>-0.876696</td>\n",
       "      <td>1.618118</td>\n",
       "      <td>0.340293</td>\n",
       "      <td>0.593094</td>\n",
       "      <td>-0.098901</td>\n",
       "      <td>0.672027</td>\n",
       "      <td>-0.035843</td>\n",
       "      <td>1.512771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17445</th>\n",
       "      <td>-0.447603</td>\n",
       "      <td>-0.460146</td>\n",
       "      <td>-1.952710</td>\n",
       "      <td>-0.342597</td>\n",
       "      <td>-0.495226</td>\n",
       "      <td>-0.449818</td>\n",
       "      <td>-0.430461</td>\n",
       "      <td>0.144701</td>\n",
       "      <td>-0.299213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14265</th>\n",
       "      <td>1.232698</td>\n",
       "      <td>-1.382172</td>\n",
       "      <td>0.586545</td>\n",
       "      <td>-0.561490</td>\n",
       "      <td>-0.409306</td>\n",
       "      <td>-0.007434</td>\n",
       "      <td>-0.380587</td>\n",
       "      <td>-1.017864</td>\n",
       "      <td>-0.984220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>-0.108551</td>\n",
       "      <td>0.532084</td>\n",
       "      <td>1.142008</td>\n",
       "      <td>-0.119565</td>\n",
       "      <td>-0.256559</td>\n",
       "      <td>-0.485877</td>\n",
       "      <td>-0.314962</td>\n",
       "      <td>-0.171488</td>\n",
       "      <td>-0.957408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "14196   1.272587 -1.372811            0.348490     0.222569        0.211228   \n",
       "8267    0.709162 -0.876696            1.618118     0.340293        0.593094   \n",
       "17445  -0.447603 -0.460146           -1.952710    -0.342597       -0.495226   \n",
       "14265   1.232698 -1.382172            0.586545    -0.561490       -0.409306   \n",
       "2271   -0.108551  0.532084            1.142008    -0.119565       -0.256559   \n",
       "\n",
       "       population  households  median_income  median_house_value  \n",
       "14196    0.768276    0.322906      -0.326196           -0.901189  \n",
       "8267    -0.098901    0.672027      -0.035843            1.512771  \n",
       "17445   -0.449818   -0.430461       0.144701           -0.299213  \n",
       "14265   -0.007434   -0.380587      -1.017864           -0.984220  \n",
       "2271    -0.485877   -0.314962      -0.171488           -0.957408  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train_num_set = (train_num_set - means) / stds\n",
    "scaled_train_num_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-writer",
   "metadata": {},
   "source": [
    "---\n",
    "### 1.2 사용자 정의 스케일링 층\n",
    "전역변수를 다루기보다 사이킷런의 StandardScaler 처럼 사용자 정의 층을 정의할 수도 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "competent-gnome",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "class StandardizationLayer(keras.layers.Layer):\n",
    "    def adapt(self, data_sample):\n",
    "        self.means_ = np.mean(data_sample, axis=0)\n",
    "        self.stds_ = np.std(data_sample, axis=0)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        reutnr (inputs - self.means_) / (self.stds_ + keras.backend.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "visible-toolbox",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_layer = StandardizationLayer()\n",
    "std_layer.adapt(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "golden-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(std_layer)\n",
    "model.compile(loss=\"mse\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-trunk",
   "metadata": {},
   "source": [
    "물론 위에 만든 것과 동일한 역할을 해주는 층이 이미 존재함.  \n",
    "**keras.layers.Normalization** 층을 사용하면 됨."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-solid",
   "metadata": {},
   "source": [
    "---\n",
    "## 원-핫 인코딩\n",
    "ocean_proximity 특성의 경우 \"<1H OCEAN\", \"INLAND\", \"NEAR OCEAN\", \"NEAR BAY\", \"ISLAND\" 다섯 개의 값이 가능한 **범주형 특성**임  \n",
    "이 특성을 신경망에 주입하기 전에 인코딩해야 함.  \n",
    "> 범주 개수가 작으므로 **원-핫 인코딩** 을 사용할 수 있음.\n",
    "\n",
    "먼저 **룩업 테이블** 을 사용하여 각 범주를 인덱스(0 ~ 4)로 매핑해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "thick-quantity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "vocab = [key[0] for key in train_cat_set.value_counts().keys()]\n",
    "indices = tf.range(len(vocab), dtype=tf.int64)\n",
    "table_init = tf.lookup.KeyValueTensorInitializer(vocab, indices)\n",
    "num_oov_buckets = 2\n",
    "table = tf.lookup.StaticVocabularyTable(table_init, num_oov_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "collaborative-ottawa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.lookup_ops.StaticVocabularyTable at 0x1f8a3fb75b0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-indonesian",
   "metadata": {},
   "source": [
    "- **vocab** : 먼저 **어휘 사전** 을 정의함. 가능한 모든 범주의 리스트\n",
    "- **indices** : 그 다음 범주에 해당하는 인덱스(0 ~ 4까지)의 텐서를 만듦.\n",
    "- **table_init** : 그 다음 범주 리스트와 해당 인덱스를 전달하여 **룩업 테이블**의 초기화 객체를 만듦. 이 예에서는 이미 이 데이터를 갖고 있으므로 **KeyValueTensorInitializer** 를 사용함. (만약 범주가 텍스트 파일에 라인당 하나의 범주로 나열되어 있다면 **TextFileInitializer** 사용)\n",
    "- **num_oob_buckets**, **table** : 초기화 객체와 **oov(out of vocabulary) 버킷** 을 지정하여 룩업 테이블을 만듦.  \n",
    "    > 어휘 사전에 없는 범주를 찾으면 룩업 테이블이 계산한 이 범주와 해시값을 이용하여 oov버킷 중 하나에 할당함. \n",
    "    \n",
    "    인덱스는 알려진 범주 다음부터 시작함. 따라서 이 예제에서 두 개의 oov버킷의 인덱스는 5와 6이 됨."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-rough",
   "metadata": {},
   "source": [
    "**oov 버킷** 은 왜 사용하는가?\n",
    "범주 개수가 많고(우편번호, 도시, 단어, 상품, 사용자 등), 데이터셋이 크거나 범주가 자주 바뀐다면 전체 범주 리스트를 구하는 것이 어려울 수 있음.  \n",
    "> 한 가지 해결책은 샘플 데이터를 기반으로 어휘 사전을 정의하고 샘플 데이터에 없는 다른 범주를 oov 버킷에 추가하는 것임.  \n",
    "\n",
    "학습 도중에 발견되는 알려지지 않은 범주가 많을수록 더 많은 oov버킷을 사용해야 함.  \n",
    "실제 oov버킷이 충분하지 않으면 충돌이 발생할 수도 있음. 즉 다른 범주가 동일한 버킷에 할당되는 것. 따라서 신경망은 두 범주를 구분할 수 없을 것.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-occasions",
   "metadata": {},
   "source": [
    "이제 **룩업 테이블을 이용해서 몇 개의 범주 특성을 원-핫 인코딩** 해보겠음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-senior",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
