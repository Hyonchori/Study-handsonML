{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acoustic-grass",
   "metadata": {},
   "source": [
    "# 연습 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-purple",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. He 초기화를 사용하여 무작위로 선택한 값이라면 모든 가중치를 같은 값으로 초기화해도 괜찮을까요?\n",
    "\n",
    "**안된다**  \n",
    "모든 가중치는 독립적으로 샘플링되어야 함. 즉 같은 초깃값을 가지면 안 됨.  \n",
    "가중치를 무작위로 샘플링하는 중요한 목적은 대칭성을 피하기 위함임. 모든 가중치가 0이 아니더라고 같은 초깃값을 가지면 대칭성이 깨지지 않고(어떤 층에 있는 모든 뉴런이 동일한 상태) 역전파로 이를 해결할 수 없음. 이는 층마다 하나의 뉴런이 있는 것과 같으므로 수렴하는데 오랜 시간이 걸림.\n",
    "\n",
    "---\n",
    "## 2. 편향을 0으로 초기화해도 괜찮은 것인가?\n",
    "**괜찮다**  \n",
    "편향을 0으로 초기화하는 것은 아무 상관이 없음.\n",
    "\n",
    "\n",
    "---\n",
    "## 3. ReLU보다 SELU 활성 함수가 나은 세 가지는 무엇인가?\n",
    "- SELU 함수는 음수를 받을 수 있어서 뉴런의 평균 출력이 ReLU 활성함수보다 일반적으로 0에 더 가까움. -> **그래디언트 소실 문제 완화**\n",
    "- 도함수의 값은 항상 0이 아니라서 ReLU 에서 일어나는 **죽은 뉴런 현상을 피할 수 있음**\n",
    "- 조건이 맞을 때 SELU함수를 사용하면 모델이 자기 정규화되어 **그레디언트 폭주, 소실 문제를 해결할 수 있음**\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "## 4. 어떤 경우에 SELU, LeakyReLU(또는 그 변종), ReLU, tanh, 로지스틱, 소프트맥스와 같은 활성 함수를 사용해야 하는가?\n",
    "- **SELU**함수가 기본값으로 좋음.\n",
    "- 가능한 빠른 신경망을 원한다면 대신 **LeakyReLU(또는 그 변종)**을 사용할 수 있음.\n",
    "- 위 두 부류보다 **ReLU**가 훨씬 간단해서 그래도 사람들이 많이 선호함. 그리고 특정 상황에서는 정확히 0을 출력하는 특성이 유용할 수 있음\n",
    "- **tanh**는 -1 ~ 1 사이의 값을 가져야 하는 출력층에 사용됨. 최근엔 순환신경망을 제외하고 은닉층에 사용하진 않다고 함\n",
    "- **로지스틱 함수**는 확률을 추정할 필요가 있을 때 사용됨. 역시 최근엔 대체로 은닉층에 사용하진 않다고 함\n",
    "- **소프트맥스 함수**는 상호 배타적인 클래스에 대한 확률을 출력할 때 사용됨. 역시 은닉층에 사용하진 않음.\n",
    "\n",
    "---\n",
    "## 5. SGD 옵티마이저를 사용할 때 momentum 하이퍼파라미터를 너무 1에 가깝게 하면(0.99999999) 어떤 일이 일어날까요?\n",
    "\n",
    "momentum 파라미터를 너무 1에 가깝게 셋팅하면 알고리즘이 **전역 최적점 방향으로 빠르게 진행되겠지만 그 최솟값을 지나칠 수 있음.**  \n",
    "그런 다음 느려져서 되돌아오고 다시 가속되어 또 지나치게 되는 식임. 수렴하기 전에 이렇게 여러 번 진동하게 됨.  \n",
    ">따라서 적당한 값을 사용할 때보다 수렴속도가 느려짐\n",
    "\n",
    "---\n",
    "## 6. 희소 모델을 만들 수 있는 세 가지 방법은 무엇인가요?\n",
    "- 모델을 학습한 뒤에 **작은 가중치를 0으로 만드는 것.**\n",
    "- 학습하는 동안 옵티마이저에 희소한 모델을 만들도록 **l1 규제를 사용하는 것**\n",
    "- **텐서플로의 모델 최적화 도구**를 사용하는 것\n",
    "\n",
    "\n",
    "---\n",
    "## 7. 드롭아웃이 학습 속도를 느리게 만드는가? 추론 속도도 느리게 만드는가? MC 드롭아웃은 어떤가?\n",
    "\n",
    "**일반적으로 2배 정도 학습 속도를 느리게 함**  \n",
    "그러나 학습할 때만 적용하므로 추론엔 영향을 미치지 않음.  \n",
    ">MC드롭아웃은 학습할 때는 일반 드롭아웃과 똑같음. 하지만 추론할 때도 작동하기 때문에 추론 속도를 느리게 만듦.  \n",
    "그리고 MC드롭아웃을 이용할 때 더 나은 예측을 얻기 위해선 보통 10배 이상 더 많은 추론을 실행해야 함. 즉 예측 속도를 10배 정도 늦춤.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-flooring",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
