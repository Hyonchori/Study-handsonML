{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _04_preprocessing import housing, housing_prepared, housing_labels\n",
    "from _04_preprocessing import full_pipeline\n",
    "from _04_preprocessing import start_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선형회귀\n",
    "제일 기본적인 **선형회귀** 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[210644.60459286 317768.80697211 210956.43331178  59218.98886849\n",
      " 189747.55849879]\n",
      "[286600.0, 340600.0, 196900.0, 46300.0, 254500.0]\n"
     ]
    }
   ],
   "source": [
    "some_data = housing.iloc[:5]\n",
    "some_prepared = full_pipeline.transform(some_data)\n",
    "print(lin_reg.predict(some_prepared))\n",
    "\n",
    "some_labels = housing_labels.iloc[:5]\n",
    "print(list(some_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임의의 데이터를 학습한 모델에 넣는 방법  \n",
    "일단 성능이 형편없어 보인다;;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68628.19819848922\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "lin_predictions = lin_reg.predict(housing_prepared)\n",
    "lin_mse = mean_squared_error(housing_labels, lin_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(lin_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습에 쓰인 전체 데이터셋에 대한 성능 지표  \n",
    "예측할 값인 중간 주택 가격의 범위가 120,000 ~ 265,000인데 이 정도면 거의 뭐 못 쓴다고 보면 된다.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 디시전트리\n",
    "이번에는 **디시전트리** 모델을 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "tree_predictions = tree_reg.predict(housing_prepared)\n",
    "tree_mse = mean_squared_error(housing_labels, tree_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "print(tree_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "??? 오차가 전혀 없다고 한다.  \n",
    "말도 안된다고 생각한다면 맞는 말이다. 이것이 **오버피팅**이다.  \n",
    "이런 경우를 확인하기 위하여 훈련세트를 또 쪼개서 **검증 세트**를 만드는 것이다.  \n",
    "  \n",
    ">훌륭한 방법인 **K-겹 교차 검증**을 사용해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(tree_reg, housing_prepared, housing_labels,\n",
    "                        scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cv**매개변수는 몇 겹으로 쪼개서 할 것이냐를 나타냄\n",
    ">**cross_val_score**클래스의 **scoring**매개변수는 비용함수(낮을수록 좋은)가 아니라  \n",
    ">효용함수(높을수록 좋은)를 받기를 기대하기 때문에 에러에 -를 붙인 값을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"점수: \", scores)\n",
    "    print(\"평균: \", scores.mean())\n",
    "    print(\"표준편차: \", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "점수:  [68362.93967039 67385.18193727 73082.56972422 67675.36294787\n",
      " 71688.32158736 74894.40892908 72008.96809207 71611.99777609\n",
      " 76347.16740791 69307.70412735]\n",
      "평균:  71236.46221996029\n",
      "표준편차:  2886.883980878265\n"
     ]
    }
   ],
   "source": [
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증세트에 대해 성능을 보니 선형회귀 모델보다 형편없음을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,\n",
    "                            scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "점수:  [66782.73843989 66960.118071   70347.95244419 74739.57052552\n",
      " 68031.13388938 71193.84183426 64969.63056405 68281.61137997\n",
      " 71552.91566558 67665.10082067]\n",
      "평균:  69052.46136345083\n",
      "표준편차:  2731.6740017983498\n"
     ]
    }
   ],
   "source": [
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 랜덤포레스트\n",
    "디시전트리의 **앙상블**버전인 **랜덤포레스트**모델 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels,\n",
    "                                scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "점수:  [49312.41406162 47960.72824476 49228.72252359 52378.31003832\n",
      " 49740.04221191 53040.48766161 48554.21486233 48172.28323068\n",
      " 53343.06696002 50344.70774369]\n",
      "평균:  50207.49775385235\n",
      "표준편차:  1910.2351889945664\n"
     ]
    }
   ],
   "source": [
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18575.80571921274"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_predictions = forest_reg.predict(housing_prepared)\n",
    "forest_mse = mean_squared_error(housing_labels, forest_predictions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 셋 중에는 랜덤포레스트가 제일 낫지만 여전히 훈련셋에 대한 성능보다 검증셋에 대한 성능이 훨씬 떨어짐  \n",
    "아직도 오버피팅이라는 얘기  \n",
    "  \n",
    "오버피팅을 방지하기 위한 방법으론\n",
    "> **모델을 간단히 하기**  \n",
    "> **학습시 제한(규제)를 가하기**  \n",
    "> **더 많은 훈련 데이터를 모으기**  \n",
    "  \n",
    "여러 종류의 머신러닝 알고리즘으로 하이퍼파라미터 튜닝에 너무 많은 시간을 들이지 않으면서  \n",
    "다양한 모델을 시도해봐야 함 (다양한 커널의 SVM, 신경망 등)  \n",
    "가능한 2~5개 정도의 모델을 선정하는 것이 목적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmy_model_loaded = joblib.load(my_model.pkl)\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(forest_reg, \"my_model.pkl\")\n",
    "\n",
    "'''\n",
    "my_model_loaded = joblib.load(my_model.pkl)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델을 저장하고 불러오는 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
