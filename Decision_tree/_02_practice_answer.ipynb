{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 백만 개의 샘플을 가진 학습 데이터셋에서 규제 없이 학습한 결정 트리의 깊이는 대략 얼마일까요?\n",
    "균형이 잘 잡힌 이진 트리의 깊이는 log2(샘플수)를 반올림한 것과 같다. 따라서 학습데이터셋이 백만 개라면 대략 20층 정도 될 것. 물론 균형이 잘 잡히지 않는다면 좀 더 깊어질 수 있음.\n",
    "\n",
    "---\n",
    "## 2. 한 노드의 지니 불순는 보통 그 부모 노드보다 작을까요, 아니면 클까요? 일반적으로 작거나 클까요, 아니면 항상 작거나 클까요?\n",
    "한 노드의 지니 불순도는 일반적으로 부모의 불순도보다 낮다.\n",
    "\n",
    "---\n",
    "## 3. 결정 트리가 학습데이터셋에 과대적합되었다면 max_depth를 줄이는 것이 좋을까요?\n",
    "모델을 규제하기 위해 max_depth는 줄여야 한다.\n",
    "\n",
    "---\n",
    "## 4. 결정 트리가 학습데이터셋에 과소적합되었다면 입력 특성의 스케일을 조정하는 것이 좋을까요?\n",
    "특성의 스케일이나 원점에 맞추어져 있는지는 결정 트리 학습에 전혀 관계없음.\n",
    "\n",
    "---\n",
    "## 5. 백만 개의 샘플을 가진 학습 데이터셋에 결정 트리를 학습하는데 한 시간이 걸렸다면, 천만개의 샘플을 가진 학습 데이터셋에 결정 트리를 훈련시킬 때 대략 얼마나 걸릴까요?\n",
    "결정트리 학습의 계산 복잡도는 (특성수) x (샘플수) x log(샘플수) 임. 샘플수가 10배 되었을 때 대량 11.7배 늘어남.\n",
    "\n",
    "---\n",
    "## 6. 십만 개의 샘플을 가진 학습 데이터셋이 있을 때 presort=True로 지정하는 것이 훈련 속도를 높일까요?\n",
    "데이터셋의 샘플수가 수천개 미만일 때는 학습데이터셋을 사전에 정렬하여 학습 속도를 높일 수 있음. 하지만 십만개 정도면 오히려 매우 느려질 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
